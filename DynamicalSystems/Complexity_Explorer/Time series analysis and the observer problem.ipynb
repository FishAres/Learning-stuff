{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing timeseries\n",
    "\n",
    "Spectral methods only work when a signal is periodic and linear. Otherwise superposition won't work.\n",
    "\n",
    "Wavelets and spectrograms are used to overcome some of these problems. \n",
    "\n",
    "Statistical techniques work for timeseries that are *stationary* wrt that statistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Projections are problematic because:\n",
    "\n",
    "* If the system is autonomous, there can only be one \"downhill\" direction for the system to follow\n",
    "\n",
    "* If there is a projection, you are breaking the topology of the attractor. \n",
    "\n",
    "One of the holy grails of control theory is the observer problem: deducing the internal variables and values of the system from the system's outputs.\n",
    "\n",
    "In order to do this, you need to \"undo\" a projection, which sounds ill posed but can be done with Delay Coordinate Embedding.\n",
    "\n",
    "This is similar to the inverse problem. \n",
    "\n",
    "Using the derivatives (e.g. angular velocity from angle) is problematic since it magnifies noise, both from the errors in the derivative and possibly in measurement noise of one system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay Embeddings\n",
    "\n",
    "With proper delay and dimensions, the embedded dynamics are diffeomorphic (have same topology) as the original dynamics. \n",
    "\n",
    "Any $\\tau$ that inflates even a little bit will result in non-crossing trajectories. The tau needs to be > 0 (in practice big enough to overcome machine epsilon wrt the computations you're using).\n",
    "\n",
    "Obviously, avoid using a delay that's a multiple of the period is a bad idea.\n",
    "\n",
    "**Invariants like the Lyapunov exponent are invariant to transformations that preserve topology**\n",
    "\n",
    "Even though the trajectories look different, if they have the same topology we can still learn a lot of the critical aspects of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of dimensions is critical: m needs to be > 2x the number of state variables (relation to Nyquist?). \n",
    "\n",
    "Newer papers show sufficient to be >2x the capacity dimension of the original number. \n",
    "\n",
    "### What do you do if you don't know anything about the system you're studying?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial embeddings for systems that aren't time-based?\n",
    "\n",
    "**Topology 101***\n",
    "\n",
    "Size doesn't really matter. Only the number of pieces or number of holes matter. e.g. a coffee mug and a donut have the same topology (the coffee mug has a handle). You can deform one into the other without destroying or creating pieces or holes. (Betty numbers?). This is called a *diffeomorphism*: 1->1, differentiable in both dimensions.\n",
    "\n",
    "Bifurcations are *topological* changes in the attractor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating embedding parameters\n",
    "\n",
    "\n",
    "With increasing delays, the attractor begins to \"fold\" itself. The folded version is still topologically equivalent. \n",
    "\n",
    "The choice of tau > 0 in the delay embedding is analogous to base vectors in linear algebra: \n",
    "\n",
    "Any two vectors that aren't parallel can be used linearly to recover any point in R2 and fill the plane. \n",
    "\n",
    "**Similarly, a time difference can be a nonlinear basis to reconstruct an attractor**\n",
    "\n",
    "We want the \"delay vectors\" to be maximally independent. A naive (but sometimes good) way of choosing a tau is by looking at the autocorrelation and choosing its first zero value. The naivety is due to the linear nature of autocorrelation. \n",
    "\n",
    "### Why choose the first zero? \n",
    "\n",
    "\"Wrapping around\" of the basis vectors loosely causes the \"attractor folding\" seen with delays that are too large.\n",
    "\n",
    "\n",
    "Fraser and Swinney propose a mutual information based technique to get the embedding delay. In an information theoretic sense, two orthogonal vectors \"share the least information\" about each other. The first minimum of the mutual information curve is the most \"independent\" delay. Some argue that the first peak is actually a better heuristic, since it allows more \"faithful\" reconstruction of the attractor with a high enough delay to meaningfully unfold the dynamics.\n",
    "\n",
    "\n",
    "This is just a numerical concern, btw. \n",
    "\n",
    "\n",
    "## Choosing dimensions\n",
    "\n",
    "\"False neighbors\" technique: increases dimension until false crossings stop occuring (mostly). \n",
    "\n",
    "-> Measure the distance between two nearby points when inflating the dynamics (ratio of true neighbors to false neighbors: ~90%). This is not \"reversible\": it doesn't give you any information about the true number of dimensions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaotic systems are broadband: have meaningful content in every frequency.\n",
    "\n",
    "The peaks are the stabler nonperiodic orbits.\n",
    "\n",
    "**Noise destroys nearest neighbor relationships**\n",
    "\n",
    "Roughly you need k^d datapoints with a d-dimensional system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
