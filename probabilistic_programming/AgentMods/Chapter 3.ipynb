{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents as probabilistic programs\n",
    "\n",
    "In general, the idea is that we want to take an action $\\alpha$ from the set $A$ of all actions. The consequences of each action are represented by a transition function $T: S \\times A \\rightarrow S$. Preferences are indicated by a (real-valued) utility function $U: S \\rightarrow \\mathbb{R}$\n",
    "\n",
    "The decision rule is to maximize utility:\n",
    "\n",
    "$$arg max_{\\alpha \\in A} U(T(s,\\alpha))$$\n",
    "\n",
    "\n",
    "### However, the environment of interest can be variable:\n",
    "\n",
    "In the case that the utility of certain actions can vary, we would want to use the *expected utility* over different successor states $s' \\sim T(s,a)$:\n",
    "\n",
    "$$ max_{\\alpha \\in A}\\mathbb{E}(U(T(s,a)))$$\n",
    "\n",
    "Better yet, we can use *soft conditioning* (i.e. softmax). \n",
    "\n",
    "$$C(a;s) \\propto e^{\\alpha \\mathbb{E}(U(T(s,a))))}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
